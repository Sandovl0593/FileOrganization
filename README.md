<a name="readme-top"></a>

<div align="center">
  <a href="https://https://github.com/Auky216/Cachimbo">
  </a>
  <h1>File Organization</h1>
</div>
<h3 align="center">Base de Datos II - Proyecto 01</h3>

## Integrantes

- Espinoza Herrera, Marcela
- Sandoval Huaman칤, Adrian
- Guill칠n Rodriguez, Fernando
- Lindo Pe침a, Ximena Nicolle

## Introducci칩n

### Objetivo del Proyecto:

El objetivo de nuestro proyecto fue mejorar significativamente la eficiencia en la b칰squeda y gesti칩n de registros en memoria secundaria. Para lograr esto, nos enfocamos en los siguientes aspectos clave:

- Implementaci칩n de Estructuras de Datos: Utilizamos t칠cnicas avanzadas como Sequential File, ISAM-Sparse Index y Extendible Hashing para estructurar los archivos. Esto nos permiti칩 optimizar las b칰squedas y garantizar accesos m치s r치pidos y eficientes.

- Desarrollo de Algoritmos de B칰squeda: Implementamos algoritmos de b칰squeda avanzados que optimizan el tiempo de ejecuci칩n durante el acceso a los datos. Estos algoritmos est치n dise침ados para integrarse y aprovechar al m치ximo las estructuras de datos empleadas, mejorando significativamente la eficiencia en las operaciones de b칰squeda y manipulaci칩n de datos.

- Optimizaci칩n de Consultas SQL: Integrando un parser de SQL que trabaja directamente con nuestras estructuras de datos, conseguimos que las consultas SQL sean m치s eficaces. Este parser facilita la ejecuci칩n de consultas complejas, mejorando la interacci칩n con los datos y la realizaci칩n de operaciones b치sicas como inserci칩n y eliminaci칩n.

Estas iniciativas nos permitieron no solo mejorar la gesti칩n de los datos en nuestros proyectos, sino tambi칠n obtener resultados m치s efectivos y eficientes en tiempo real.



### Descripci칩n del Dominio de Datos Utilizados

Para este proyecto, seleccionamos el conjunto de datos de la **NBA Database** disponible en [Kaggle](https://www.kaggle.com/datasets/wyattowalsh/basketball). Este dataset proporciona informaci칩n exhaustiva sobre jugadores y partidos de la NBA. Optamos por trabajar con dos archivos CSV espec칤ficos que son esenciales para nuestro proyecto:

**1. Informaci칩n Com칰n de los Jugadores (`common_player_info.csv`):**
El primer archivo contiene detalles sobre los jugadores, incluyendo identificaciones, nombres, fechas de nacimiento, escuelas, pa칤ses, y m치s. Espec칤ficamente, el archivo incluye 4,172 filas y 16 columnas, con los siguientes campos:

- `person_id`: Identificaci칩n 칰nica del jugador (tipo `double`).
- `display_first_last`: Nombre completo del jugador (tipo `char[24]`).
- `birthdate`: Fecha de nacimiento (tipo `char[10]`).
- `school`: Escuela o universidad (tipo `char[31]`).
- `country`: Pa칤s de origen (tipo `char[24]`).
- `height`: Altura (tipo `char[4]`).
- `weight`: Peso (tipo `double`).
- `season_exp`: Experiencia en temporadas (tipo `double`).
- `jersey`: N칰mero de camiseta (tipo `char[7]`).
- `position`: Posici칩n en el juego (tipo `char[14]`).
- `team_id`: Identificaci칩n del equipo (tipo `double`).
- `team_name`: Nombre del equipo (tipo `char[13]`).
- `team_abbreviation`: Abreviatura del equipo (tipo `char[3]`).
- `team_city`: Ciudad del equipo (tipo `char[25]`).
- `from_year`: A침o de inicio en la NBA (tipo `double`).
- `to_year`: 칔ltimo a침o en la NBA (tipo `double`).

**2. Informaci칩n de Partidos (`game.csv`):**
El segundo archivo registra los partidos jugados en la liga durante los 칰ltimos 5 a침os, incluyendo informaci칩n sobre equipos, fechas, y resultados. Contiene 7,213 filas y 16 columnas, con campos como:

- `season_id`: Identificaci칩n de la temporada (tipo `double`).
- `team_id_home`: Identificaci칩n del equipo local (tipo `double`).
- `team_abbreviation_home`: Abreviatura del equipo local (tipo `char[3]`).
- `team_name_home`: Nombre del equipo local (tipo `char[22]`).
- `game_id`: Identificaci칩n del juego (tipo `double`).
- `game_date`: Fecha del juego (tipo `char[10]`).
- `matchup_home`: Enfrentamiento en casa (tipo `char[11]`).
- `pts_home`: Puntos anotados por el equipo local (tipo `double`).
- `plus_minus_home`: Diferencia de puntos del equipo local (tipo `double`).
- `team_id_away`: Identificaci칩n del equipo visitante (tipo `double`).
- `team_abbreviation_away`: Abreviatura del equipo visitante (tipo `char[3]`).
- `team_name_away`: Nombre del equipo visitante (tipo `char[25]`).
- `matchup_away`: Enfrentamiento fuera de casa (tipo `char[9]`).
- `pts_away`: Puntos anotados por el equipo visitante (tipo `double`).
- `plus_minus_away`: Diferencia de puntos del equipo visitante (tipo `double`).
- `season_type`: Tipo de temporada (tipo `char[14]`).

Cada archivo fue elegido por su relevancia y la riqueza de sus datos, que son cruciales para la implementaci칩n de nuestras t칠cnicas de organizaci칩n de archivos y para las pruebas de nuestras consultas y algoritmos de b칰squeda.


### Resultados Esperados al Aplicar las T칠cnicas de Indexaci칩n

En este proyecto, nos proponemos evaluar y comparar el impacto de las t칠cnicas de indexaci칩n en la gesti칩n de datos en memoria secundaria. Con base en las implementaciones y pruebas realizadas, anticipamos los siguientes resultados:

- **Evaluaci칩n de Rendimiento:** Mediante pruebas controladas, determinaremos el rendimiento de cada t칠cnica de indexaci칩n observando aspectos cr칤ticos como los tiempos de ejecuci칩n y los accesos al disco duro. Esto nos ayudar치 a identificar la t칠cnica m치s efectiva para nuestro contexto de uso.

- **Optimizaci칩n de Acceso a Datos:** Esperamos que las t칠cnicas de indexaci칩n permitan una reducci칩n significativa en la cantidad de accesos a la memoria secundaria, optimizando as칤 el proceso de consulta de datos.

- **Eficiencia en Operaciones de Datos:** Mediante el uso de estructuras de datos especializadas, buscamos mejorar la eficiencia de operaciones fundamentales como la inserci칩n, b칰squeda, recuperaci칩n y eliminaci칩n de registros.

- **Comparaci칩n entre Estructuras:** Estableceremos cu치l de las estructuras de datos implementadas demuestra mayor eficacia en t칠rminos de tiempo de ejecuci칩n y manejo de grandes vol칰menes de informaci칩n.

- **Organizaci칩n de Datos:** A trav칠s de estas t칠cnicas, tambi칠n pretendemos mejorar la organizaci칩n de los registros dentro de la memoria secundaria, facilitando una recuperaci칩n m치s r치pida y una gesti칩n m치s eficiente del espacio de almacenamiento.

Con estos resultados, buscamos no solo validar la aplicabilidad de las t칠cnicas aprendidas en clase, sino tambi칠n demostrar su utilidad en escenarios reales de manejo de datos a gran escala.



## Tecnicas Utilizadas


### Sequential File
El **Sequential File** emplea una estructura de datos lineal que facilita el acceso secuencial a los registros. Este m칠todo utiliza dos archivos: uno principal para los datos regulares y otro auxiliar para manejar inserciones excepcionales o temporales. Los registros en el archivo principal est치n ordenados, lo que permite b칰squedas eficientes.

#### Inserci칩n:
La inserci칩n en el archivo secuencial depende de la posici칩n relativa del nuevo registro respecto a los existentes, bas치ndose en la clave primaria:

1. **Verificaci칩n del Orden:** Si el nuevo registro tiene una clave mayor que cualquier registro existente en el archivo principal, se a침ade al final de este archivo.
2. **Archivo Auxiliar:** Si el nuevo registro no sigue el orden secuencial, se inserta en el archivo auxiliar.
3. **Actualizaci칩n de Punteros:** Independientemente de su ubicaci칩n, los punteros asociados deben actualizarse para reflejar la nueva entrada.
4. **Reorganizaci칩n del Archivo Auxiliar:** Cuando el archivo auxiliar alcanza su capacidad m치xima, se realiza una reorganizaci칩n para integrar estos registros al archivo principal, manteniendo el orden.

#### B칰squeda:
La eficacia de la b칰squeda depende del archivo en el que se almacene el registro:

1. **B칰squeda Binaria en Archivo Principal:** Se utiliza una b칰squeda binaria para encontrar registros r치pidamente gracias al orden secuencial.
2. **Escaneo del Archivo Auxiliar:** Si la b칰squeda en el archivo principal falla, se recorre el archivo auxiliar de manera secuencial.
3. **B칰squeda por Rango:** Inicia desde el primer registro del archivo principal y continua agregando registros que cumplan con las condiciones especificadas hasta que se encuentre uno que no lo haga.

#### Eliminaci칩n:
La eliminaci칩n requiere una cuidadosa gesti칩n de punteros para mantener la integridad de la estructura de datos:

1. **Localizaci칩n del Registro:** Identificar el registro a eliminar por su clave y determinar sus registros predecesor y sucesor.
2. **Actualizaci칩n de Punteros:** El puntero del registro eliminado se ajusta para reflejar su eliminaci칩n, com칰nmente configur치ndolo a un valor especial que indica que est치 vac칤o o inactivo.
3. **Mantenimiento del Orden:** Asegurar que los punteros en los registros adyacentes se actualicen para mantener el acceso secuencial coherente.

### ISAM
El **ISAM** es una t칠cnica de organizaci칩n de archivos que combina el acceso secuencial con un m칠todo de indexaci칩n para mejorar el rendimiento en entornos de memoria secundaria. Utiliza un archivo de datos principal donde los registros est치n ordenados, y un archivo de 칤ndice que permite accesos r치pidos a los datos a trav칠s de claves indexadas.

#### Inserci칩n:
La inserci칩n en ISAM sigue un proceso estructurado para mantener la eficiencia del 칤ndice:

1. **Localizaci칩n del Punto de Inserci칩n:** Utilizando el 칤ndice, se determina la posici칩n adecuada en el archivo de datos donde el registro debe ser insertado para mantener el orden.
2. **Inserci칩n en el Archivo de Datos:** Si hay espacio suficiente en la p치gina de datos, el registro se inserta directamente. Si no, se procede a una divisi칩n de p치gina.
3. **Actualizaci칩n del 칈ndice:** Cada inserci칩n puede requerir una actualizaci칩n del archivo de 칤ndice para reflejar la nueva entrada y mantener la integridad de los punteros.
4. **Manejo de P치ginas de Overflow:** Si la inserci칩n en la ubicaci칩n adecuada no es posible debido al espacio, se utiliza una p치gina de overflow.

#### B칰squeda:
ISAM optimiza las b칰squedas utilizando el 칤ndice para acceder directamente a los datos:

1. **B칰squeda en el 칈ndice:** Se realiza una b칰squeda binaria en el archivo de 칤ndice para localizar la p치gina de datos que contiene la clave buscada.
2. **Acceso Directo a los Datos:** Una vez identificada la p치gina, se accede directamente a ella y se realiza una b칰squeda secuencial en esa p치gina para encontrar el registro espec칤fico.
3. **Manejo de P치ginas de Overflow:** Si el registro no se encuentra en la p치gina principal, se busca en las p치ginas de overflow asociadas.

#### Eliminaci칩n:
La eliminaci칩n en ISAM debe gestionar adecuadamente tanto el archivo de datos como el 칤ndice:

1. **B칰squeda del Registro:** Utilizando el 칤ndice, se localiza la p치gina de datos donde deber칤a estar el registro.
2. **Eliminaci칩n del Registro:** El registro se elimina de la p치gina de datos. Si es necesario, se ajustan los registros en la p치gina para llenar el espacio vac칤o.
3. **Actualizaci칩n del 칈ndice:** Se actualiza el 칤ndice para reflejar la eliminaci칩n del registro.
4. **Compresi칩n de P치ginas:** Si la eliminaci칩n deja una p치gina de datos suficientemente vac칤a, se puede considerar la compresi칩n de p치ginas para optimizar el espacio.




### Extendible Hashing
El **Extendible Hashing** se caracteriza por su capacidad para gestionar datos de manera eficiente y adaptativa mediante directorios y buckets. Este m칠todo se ajusta din치micamente a los cambios en los requisitos de almacenamiento, lo que permite la modificaci칩n de su estructura de 칤ndices y almacenamiento sin sacrificar el rendimiento en las operaciones de b칰squeda, inserci칩n o eliminaci칩n. La funci칩n hash en este sistema es especialmente 칰til para realizar b칰squedas de igualdad de manera r치pida y directa. Sin embargo, es importante se침alar que, mientras es excelente para estas b칰squedas puntuales, el extendible hashing no est치 optimizado para b칰squedas por rango, debido a que la distribuci칩n de los datos en buckets no preserva un orden espec칤fico que facilite este tipo de consultas.
#### Inserci칩n:
Para insertar un elemento en el extendible hashing, se deben seguir los siguientes pasos:
1. C치lculo del Valor Binario:
   Se calcula el valor binario del atributo clave que determinar치 la posici칩n en el extendible hashing.
2. Evaluaci칩n de la Profundidad del Bucket:
   Se eval칰a la profundidad local del bucket correspondiente. Por ejemplo, si el valor binario es '101001' y la profundidad del bucket es 3, la funci칩n hash utilizar치 los tres primeros d칤gitos del binario, '101', para ubicar el bucket adecuado.

![Estructura de Hashing Din치mico](https://media.discordapp.net/attachments/1015053042959265802/1241790795644928130/image.png?ex=664b7b4d&is=664a29cd&hm=14c5418f95cc19153c6181427dd2d384d8a42cf5568734a5c2bbbcc341fc3dc6&=&format=webp&quality=lossless&width=565&height=417)

3. Gu칤a de Inserci칩n en la Estructura del 츼rbol:
   La inserci칩n se gu칤a por la estructura de un 치rbol digital, donde se inserta a la izquierda si el d칤gito relevante es 0 y a la derecha si es 1. Esto posiciona al bucket en una ubicaci칩n espec칤fica dentro de la estructura del 치rbol, funcionando como una hoja.

![Overflow](https://media.discordapp.net/attachments/1015053042959265802/1241791093507620915/image.png?ex=664b7b94&is=664a2a14&hm=49be5afa89c356b506db6f198bb795abe29089478fba64fdf713951995fa20e8&=&format=webp&quality=lossless&width=542&height=417
)

4. Verificaci칩n y Manejo de Desbordamiento:
   Se verifica si el bucket est치 lleno, lo que puede requerir una divisi칩n. En caso de desbordamiento y si se ha alcanzado la profundidad global m치xima, se crear치 un nuevo bucket incrementando la profundidad local y redistribuyendo los registros entre el nuevo y el antiguo bucket, repartiendo los datos equitativamente entre ambos.

![Redistribuir](https://media.discordapp.net/attachments/1015053042959265802/1241791520907198544/image.png?ex=664b7bf9&is=664a2a79&hm=9ca2280cfdecbd3ad9f2ca6f364031e5d95255e0b0b13da85374657bf5b70bf8&=&format=webp&quality=lossless&width=529&height=417)


#### B칰squeda:

El proceso de b칰squeda en Extendible Hashing comienza con el hashing de la llave de b칰squeda para generar un valor binario. Este valor determina el bucket espec칤fico en el directorio donde potencialmente se encuentra el registro. El proceso es el siguiente:

1. **Hash de la Llave:** Se aplica la funci칩n hash a la llave para obtener un valor hash que ser치 interpretado como un n칰mero binario.
2. **Localizaci칩n del Bucket:** Utilizando los bits m치s significativos del valor hash, determinados por la profundidad global del directorio, se identifica el bucket que debe contener el registro.
3. **B칰squeda en el Bucket:** Se busca directamente en el bucket especificado. Si el bucket tiene enlaces a buckets de desbordamiento debido a colisiones previas, la b칰squeda se extiende a estos buckets adicionales.
4. **Resultado de la B칰squeda:** Si se encuentra el registro, se devuelve; de lo contrario, se devuelve un indicador, el cual especifica que no se encontr칩 dicho registro.


#### Eliminaci칩n:
El proceso de eliminaci칩n en el Extendible Hashing involucra encontrar el registro deseado y luego removerlo del sistema. Los pasos a seguir para realizar este proceso son los siguientes:

1. **Hash de la Llave:** Al igual que en la b칰squeda, la eliminaci칩n comienza con el hashing de la llave del registro que se desea eliminar, generando un valor hash interpretado como un n칰mero binario.
2. **Localizaci칩n del Bucket:** Usando los bits m치s significativos del valor hash, y dependiendo de la profundidad global del directorio, se identifica el bucket donde te칩ricamente se encuentra el registro.
3. **B칰squeda en el Bucket:** Se examina el bucket identificado en busca del registro espec칤fico. Si hay buckets de desbordamiento asociados debido a colisiones, estos tambi칠n se revisan para encontrar el registro.
4. **Eliminaci칩n del Registro:** Si se encuentra el registro, se elimina del bucket. Si el bucket queda vac칤o o con poca carga, se pueden considerar acciones adicionales como la fusi칩n de buckets o la reorganizaci칩n para mantener la eficiencia del hashing.
5. **Manejo de Desbordamientos:** Si se eliminan registros de un bucket de desbordamiento, se revisa si es posible simplificar la estructura eliminando el bucket de desbordamiento o redistribuyendo los registros restantes.
6. **Resultado de la Eliminaci칩n:** Se actualiza la estructura del directorio si es necesario, y se devuelve un indicador de 칠xito o fallo de la operaci칩n de eliminaci칩n.


## An치lisis Comparativo (Respecto a los Accesos de Memoria Secundaria):

### Inserci칩n:
- Sequiential File: O(n)
- ISAM: O(log n)
- Extendible Hashing: O(k)


Al analizar estas complejidades llegamos a la conclusi칩n de que tanto el ISAM como el Extendible Hashing, son las mejores opciones para insertar registros. Esto se debe ya que, el Sequential File puede requerir reorganizaciones costosas cuando su archivo auxiliar se llena, un problema que ISAM y Extendible Hashing evitan mediante el uso eficiente de 칤ndices y divisi칩n de buckets, respectivamente. Esto les permite manejar inserciones de manera m치s eficaz, especialmente bajo cargas elevadas.


### B칰squeda:
- Sequiential File: O(log n)
- ISAM: O(log n + k)
- Extendible Hashing: O(k)

Al comparar las complejidades de b칰squeda, ISAM y Extendible Hashing proporcionan ventajas claras sobre Sequential File, especialmente en entornos donde las b칰squedas son frecuentes y la eficiencia es crucial. ISAM, al emplear una mezcla de b칰squeda binaria y secuencial (debido al componente "k"), ofrece una soluci칩n equilibrada entre rendimiento y simplicidad estructural. Extendible Hashing, con una complejidad de O(k) donde k es el n칰mero de operaciones en el bucket afectado, sobresale en escenarios donde la distribuci칩n de los datos es uniforme, permitiendo accesos extremadamente r치pidos y directos.

### Eliminaci칩n:

- Sequiential File: O(n logn) + O(k)
- ISAM: O(n)
- Extendible Hashing: O(k)


En cuanto a eliminaci칩n, Extendible Hashing muestra una vez m치s su eficiencia con una complejidad de O(k), destacando en entornos donde las eliminaciones son tan cr칤ticas como las inserciones. Sequential File, aunque efectivo en mantener un orden, enfrenta desaf칤os significativos ya que cada eliminaci칩n puede requerir una reorganizaci칩n completa, resultando en una complejidad m치s alta de O(n log n) m치s el coste de reubicaci칩n de otros elementos (O(k)). ISAM, por otro lado, aunque no es tan eficiente como Extendible Hashing, sigue siendo una mejor opci칩n que Sequential File debido a su estructura m치s r칤gida y menor necesidad de reorganizaci칩n completa.


Donde:

- k: Representa la cantidad de buckets en el overflow (en caso no exista, k=1)



## Parser SQL

### Descripci칩n

Utilizamos la estrategia de [Crafting Interpreters](https://craftinginterpreters.com/parsing-expressions.html) de Robert Nystrom aplicada en C++ del **curso de Compiladores** como Parser para las consultas SQL. Est치 dividida en tres clases: Token, Scanner y Parser.

### Clase Token:

Empleamos palabras reservadas, signos y patrones o lexemas de una declaraci칩n SQL.

```c++
// palabras reservadas
CREATE, TABLE, INSERT, INTO, USING, INDEX, DELETE, ON,
SELECT, FROM, WHERE, FILE, VALUES,
HASH, ISAM, SEQ, AND, OR, BETWEEN, ALL
// signos
LPAREN, RPAREN, LESS, GREATER, LESSEQUAL,
GREATEREQUAL, EQUAL, COMMA, PTCOMMA,
// lexemas
STRING, ID, NUM, FLOAT,
// error o EOF
ERR, END
```

### Clase Scanner

Utilizamos una t칠cnica intuitiva actualizando posiciones dentro de una cadena de entrada en un bucle en el m칠todo `nextToken()`, que finalmente identifica un Token:

```c++
if (c == '\'')
    // detecta cualquier car치cter hasta que coincida con '\'' -> Token STRING
else if (c == '\"')
    // detecta cualquier car치cter hasta que coincida con '\"' -> Token STRING
else if (isdigit(c))
    // detecta caracteres num칠ricos
    // si hay un punto, detecta m치s n칰meros -> Token FLOAT
    // caso contrario -> Token NUM
else if (isalpha(c) || c == '_')
    // detecta caracteres alfab칠ticos o '_'
    // si la subcadena le칤da es una palabra reservada -> Token [palabra]
    // caso contrario -> Token ID
else if (strchr("*(),;<>=", c)) {
    // para signos
    // algunos son de dos caracteres -> se leen ambos para un token
    // o caso contrario es otro token
else
    // error l칠xico
```

### Clase Parser

Utilizamos las siguientes sentencias SQL:

```
select ([atributos] | *) from [tabla];
select ([atributos] | *) from [tabla] where [k_atr] [>,<,>=,<=,=] [valor];
select ([atributos] | *) from [tabla] where [k_atr] between [inicio] and [fin];
create table [tabla] from file [nombre_archivo];
create index [id] on [tabla] using [tipo_indice]([atributo]);
insert into [tabla] values ([atributos]);
delete from [tabla] where [k_atr] = [valor];
```

Bajo estas sentencias, construimos una gram치tica para **reconocer y ejecutar** estas declaraciones de forma exitosa empleando m칠todos por cada regla de forma:

```c++
bool parseRegla() {
   if (!match(Token::[token])) {
      throw ParserError(/* error del parser */);
      return false;
   }
   // otras validaciones del parser
   // ...

   // extraemos los valores deseados
   // ejecuta la consulta
   bool execute = query(/* valores dependiendo de la regla */);

   if (!execute) return false; // validar la consulta
   return true;
}
```

La extracci칩n de los valores se basa en lo siguiente:

- Si el Token es un signo de comparaci칩n, se almacena temporalmente con `previous->type` como par치metro para la b칰squeda por rango.
- Se tienen dos objetos `unordered_map` con las tablas de Jugadores y Partidos donde almacena los pares *(atributo, 칤ndice)* donde 칤ndice puede ser `HASH`, `ISAM` o `SEQ`.
- Una `memoria` donde almacena los atributos, valores y la tabla necesarias para llamar a las consultas. As칤, una vez le칤do correctamente por el parser, extraemos esos valores para proceder con la ejecuci칩n.


## Resultados Experimentales



## Pruebas de uso y Presentaci칩n

### Sequential con rebuild

![Sequentialconrebuild](https://media.discordapp.net/attachments/996002132891271188/1241975321650270318/Imagen_de_WhatsApp_2024-05-19_a_las_23.37.55_ed00901f.jpg?ex=664c2727&is=664ad5a7&hm=76e26cea9b132a8c24de57bcc2245ed9fc9690fe20316b0f7b12f94f83cb55ef&=&format=webp&width=472&height=417)




### Video Explicativo:

[Link del Video](https://drive.google.com/file/d/1T8S1XUJBudsWqLWfm1t5l9rvNHKbVprp/view?usp=sharing
)




<a href="#top">Back to top 游댶</a>
